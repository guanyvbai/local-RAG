# 智能工作流 RAG 平台 V3.1

本项目是一个功能强大、可本地化私有部署的**智能工作流RAG平台**。它通过一个可动态配置的工作流引擎（n8n），将前端用户交互与一个高度优化的RAG（检索增强生成）后端紧密结合，并具备根据用户意图智能调度不同AI工作流的能力。

系统的核心是其先进的“**迭代式自我修正**”问答逻辑，能够通过自我反思和多轮检索，显著提升复杂问题的回答质量和准确性。

## 🌟 核心特性

* **🧠 高级RAG引擎**:
    * **迭代式自我修正**: 通过“查询改写 -> 检索 -> 评估 -> 循环修正”的闭环，显著提升复杂问题的回答准确性。
    * **双层智能路由**: 通过“向量相似度快筛 + LLM精准决策”的两层路由机制，为用户问题智能匹配最相关的知识库。

* **🤖 智能工作流调度**:
    * **动态工作流**: 用户可在前端通过动态生成的下拉菜单，明确选择执行“知识库问答”或“数据库查询”等不同的工作流。
    * **n8n 智能调度**: n8n作为系统的“智能调度中心”，根据用户的选择，将任务精确路由到最合适的处理后端。

* **📄 深度文档处理**:
    * **语义与结构感知切分**: 优先根据文档的标题、段落进行结构化切分，保证文本块的逻辑完整性。
    * **Excel“一行一向量”**: 将Excel的每一行解析为一条独立的、包含表头上下文的文本向量，极大提升了对表格数据的检索精度。
    * **多格式支持**: 支持包括 PDF, DOCX, XLSX, Markdown, JSON, TXT 在内的多种主流文件格式。

* **🚀 企业级架构**:
    * **全容器化部署**: 所有核心服务均通过 Docker Compose 进行统一编排和一键部署。
    * **本地化模型**: 依赖 Ollama 服务，可本地部署和运行大语言模型与嵌入模型，确保所有数据处理都在私有环境中完成。
    * **统一配置管理**: 所有服务的环境变量均通过 `.env` 文件进行统一管理，简化了配置和维护。

## 🏗️ 系统架构

系统采用微服务架构，由六大核心服务协同工作构成：

1.  **RAG核心后端 (`backend`)**: 基于 Python 和 FastAPI 构建，负责处理API请求、用户认证、知识库管理以及核心的RAG问答逻辑。
2.  **前端交互界面 (`frontend`)**: 基于 HTML, CSS, 和 JavaScript 构建，提供实时聊天、知识库管理和用户登录注册等功能。
3.  **智能工作流引擎 (`n8n`)**: 作为请求代理和任务调度中心，根据前端传来的工作流模式，智能分发任务。
4.  **模型服务层 (`ollama`)**: 本地化部署和运行大语言模型（LLM）与嵌入模型（Embedding Model）。
5.  **向量数据库 (`qdrant`)**: 存储文档向量并执行高效的相似度检索。
6.  **元数据库 (`mysql`)**: 存储 n8n 的工作流、执行日志以及RAG系统的用户和聊天记录。

## 🛠️ 技术栈

| 类别 | 技术 | 用途 |
| :--- | :--- | :--- |
| **后端** | Python, FastAPI | API服务, RAG核心逻辑 |
| **前端** | HTML, CSS, JavaScript | 用户交互界面 |
| **工作流** | n8n | 任务调度, 请求代理 |
| **AI模型** | Ollama, `llama3-chinese`, `Qwen3-Embedding` | LLM与嵌入模型服务 |
| **数据库**| Qdrant, MySQL | 向量存储, 元数据存储 |
| **容器化**| Docker, Docker Compose | 服务编排与部署 |

## 🚀 快速开始

### 1. 环境准备

* 已安装 Docker 和 Docker Compose。
* 已克隆本项目代码到本地。

### 2. 配置环境

1.  在项目根目录下，复制 `.env.example` (如果提供) 或直接创建一个名为 `.env` 的文件。
2.  根据您的环境，修改 `.env` 文件中的配置项，特别是 `LLM_MODEL` 和 `EMBEDDING_MODEL`，确保您本地的 Ollama 已下载这些模型。

### 3. 构建与启动

在项目根目录下，执行以下命令：

```bash
# 构建并后台启动所有服务
docker-compose up -d --build
服务在首次启动时，ollama-setup 服务会自动拉取您在 .env 文件中指定的模型，这可能需要一些时间，请耐心等待。

4. 访问应用

    前端应用: http://localhost:8000

    n8n 工作流编辑器: http://localhost:5678

5. 使用说明

    注册与登录: 首次使用请在 http://localhost:8000/register 注册账户，默认管理员账户为 admin / admin。

    管理知识库: 访问 http://localhost:8000/documents 创建知识库集合并上传您的文档。

    开始问答:

        在主聊天界面，从“选择工作流模式”下拉菜单中选择您希望执行的任务（例如“知识库问答”）。

        在输入框中提问，系统将根据您选择的模式，自动执行相应的后台工作流。